#!/usr/bin/env python3
"""
ğŸ“Š JSON â†’ FAISS ì¸ë±ìŠ¤ ìƒì„±ê¸°
ë“œë¡  ë¬¸ì„œ JSONì„ ë²¡í„°ìŠ¤í† ì–´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
"""

import os
import json
from langchain_community.embeddings import OpenAIEmbeddings, OllamaEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

# ==============
# ì„¤ì •
# ==============
JSON_PATH = "drone_docs.json"
INDEX_DIR = "vector_index"
USE_OLLAMA = True  # ë¡œì»¬ LLMì„ ì“¸ ê²½ìš° True, OpenAI APIë¥¼ ì“¸ ê²½ìš° False

# ==============
# ë³€í™˜ ë¡œì§
# ==============
def build_vectorstore():
    if not os.path.exists(JSON_PATH):
        raise FileNotFoundError(f"{JSON_PATH} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    with open(JSON_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)

    docs = []
    for item in data["documents"]:
        doc = Document(
            page_content=item["content"],
            metadata={
                "title": item.get("title"),
                "category": item.get("category"),
                "source": item.get("source"),
                "chunk_id": item.get("chunk_id"),
            },
        )
        docs.append(doc)

    print(f"ğŸ“„ ì´ {len(docs)}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    if USE_OLLAMA:
        embeddings = OllamaEmbeddings(model="llama3.1:8b")
    else:
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    vectorstore = FAISS.from_documents(docs, embeddings)
    vectorstore.save_local(INDEX_DIR)

    print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ: {INDEX_DIR}/")

if __name__ == "__main__":
    build_vectorstore()
